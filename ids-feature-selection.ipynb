{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevents column wrapping in Jupyter Notebook\n",
    "pd.set_option('display.width', 1000)  # Adjusts the display width to fit more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, label):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['label'] = label\n",
    "    df['requests_rate'] = 1\n",
    "    df = df[(df['dst_ip'].str.startswith('192.168')) & (df['protocol'] == 'TCP')]\n",
    "    return df\n",
    "\n",
    "def load_and_prepare_sets(benign_file_name, malign_file_name, aggregations, include_labels=False):\n",
    "    benign_data = load_data(f'./BCCC-CIC-IDS-2017/{benign_file_name}', 'benign')\n",
    "    ddos_data = load_data(f'./BCCC-CIC-IDS-2017/{malign_file_name}', 'malign')\n",
    "\n",
    "    benign_data['datetime'] = pd.to_datetime(benign_data['timestamp'], format='mixed')\n",
    "    benign_data.set_index('datetime', inplace=True)\n",
    "    benign_data.sort_index(inplace=True)\n",
    "\n",
    "    ddos_data['datetime'] = pd.to_datetime(ddos_data['timestamp'])\n",
    "    ddos_data.set_index('datetime', inplace=True)\n",
    "    ddos_data.sort_index(inplace=True)\n",
    "\n",
    "    bening_subnet = benign_data[(benign_data['dst_ip'].str.startswith('192.168')) & (benign_data['protocol'] == 'TCP')]\n",
    "    ddos_subnet = ddos_data[ddos_data['dst_ip'].str.startswith('192.168')]\n",
    "\n",
    "    if include_labels:\n",
    "        aggregations['label'] = lambda x: 0 if x.eq('benign').all() else 1\n",
    "        \n",
    "    bening_subnet_agg = bening_subnet.resample('1s').agg(aggregations).rename(columns={\n",
    "        'dst_port': 'unique_dst_ports',\n",
    "        'src_ip': 'unique_src_ips'\n",
    "    })\n",
    "\n",
    "    ddos_subnet_agg = ddos_subnet.resample('1s').agg(aggregations).rename(columns={\n",
    "        'dst_port': 'unique_dst_ports',\n",
    "        'src_ip': 'unique_src_ips'\n",
    "    })\n",
    "\n",
    "    if include_labels:\n",
    "        aggregations.pop('label', None)\n",
    "\n",
    "    combined_data = pd.concat([ddos_subnet, bening_subnet], ignore_index=True)\n",
    "    combined_data['datetime'] = pd.to_datetime(combined_data['timestamp'], format='mixed')\n",
    "    combined_data.set_index('datetime', inplace=True)\n",
    "    combined_data.sort_index(inplace=True)\n",
    "\n",
    "    aggregations['label'] = lambda x: -1 if x.eq('benign').all() else 1\n",
    "    combined_data_agg = combined_data.resample('1s').agg(aggregations).rename(columns={\n",
    "        'dst_port': 'unique_dst_ports',\n",
    "        'src_ip': 'unique_src_ips'\n",
    "    })\n",
    "    aggregations.pop('label', None)\n",
    "\n",
    "    features = list(bening_subnet_agg.keys())\n",
    "    return bening_subnet_agg, ddos_subnet_agg, combined_data_agg, features\n",
    "\n",
    "def score_model(y_pred, y):\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y, y_pred, target_names=[\"Normal\", \"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {\n",
    "    'syn_flag_counts': 'sum',         # Total SYN packets in 1s\n",
    "    'rst_flag_counts': 'sum',         # Total RST packets in 1s\n",
    "    'ack_flag_counts': 'sum',         # Total ACK packets in 1s\n",
    "    #'duration': lambda x: x.mean() if not x.empty else 0,               # Avg duration of connections\n",
    "    'packets_count': 'sum',           # Total packets per second\n",
    "    'fwd_packets_count': 'sum',       # Total forward packets\n",
    "    'bwd_packets_count': 'sum',       # Total backward packets\n",
    "    'dst_port': 'nunique',            # Unique destination ports per second (Port Scan)\n",
    "    'src_ip': 'nunique',              # Unique source IPs per second\n",
    "    'bytes_rate': lambda x: x.mean() if not x.empty else 0,             # Avg bytes per second\n",
    "    'requests_rate': 'count',          # Number of requests per aggregation period (1s by default)\n",
    "}\n",
    "\n",
    "bening_subnet_agg, ddos_subnet_agg, combined_data_agg, features = load_and_prepare_sets(\"friday_benign.csv\", \"ddos_loit.csv\", aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def find_best_contamination_for_isolation_forest(X, y):\n",
    "    best_f1, best_c = 0, None\n",
    "    for c in np.arange(0.01, 0.2, 0.01):\n",
    "        model = IsolationForest(contamination=c, random_state=42)\n",
    "        anomaly_score = model.fit_predict(X)\n",
    "\n",
    "        _, _, f1, _ = precision_recall_fscore_support(np.where(y == 0, 1, -1), anomaly_score, average='binary')\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_c = c\n",
    "    \n",
    "    return best_c, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.30      0.02      0.03     27889\n",
      "     Anomaly       0.00      0.06      0.00      1083\n",
      "\n",
      "    accuracy                           0.02     28972\n",
      "   macro avg       0.15      0.04      0.02     28972\n",
      "weighted avg       0.29      0.02      0.03     28972\n",
      "\n",
      "F1: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "X = combined_data_agg[features]\n",
    "y = combined_data_agg['label'].replace({'benign': -1, 'malign': 1})\n",
    "\n",
    "#c, f1 = find_best_contamination_for_isolation_forest(X, y)\n",
    "\n",
    "\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "anomaly_score = model.fit_predict(X)\n",
    "score_model(anomaly_score, y)\n",
    "\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52904, 123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/wq_7x62n7_16_jwz7q1h_v440000gn/T/ipykernel_40367/2925438520.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({'benign': -1, 'malign': 1}, inplace=True)\n",
      "/var/folders/bm/wq_7x62n7_16_jwz7q1h_v440000gn/T/ipykernel_40367/2925438520.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({'benign': -1, 'malign': 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "\n",
    "df_train = load_data(\"./BCCC-CIC-IDS-2017/monday_benign.csv\", 'benign')\n",
    "df_benign = load_data(\"./BCCC-CIC-IDS-2017/friday_benign.csv\", 'benign')\n",
    "df_ddos = load_data(\"./BCCC-CIC-IDS-2017/ddos_loit.csv\", 'malign')\n",
    "\n",
    "def categorize_ip(ip):\n",
    "    try:\n",
    "        ip_obj = ipaddress.ip_address(ip)\n",
    "        if ip_obj.is_private:\n",
    "            return \"subnet\"\n",
    "        else:\n",
    "            return \"internet\"\n",
    "    except ValueError:  # Handle invalid IPs\n",
    "        return \"unknown\"\n",
    "\n",
    "def categorize_port(port):\n",
    "    if port in [80, 443]:\n",
    "        return \"web\"\n",
    "    elif port == 53:\n",
    "        return \"dns\"\n",
    "    elif port in [25, 110, 143]:\n",
    "        return \"mail\"\n",
    "    elif port in [22, 3389]:\n",
    "        return \"remote_access\"\n",
    "    elif port in [3306, 5432, 1433]:\n",
    "        return \"database\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "def prepare_data(df):\n",
    "    df['src_ip_category'] = df['src_ip'].apply(categorize_ip)\n",
    "    df['dst_ip_category'] = df['dst_ip'].apply(categorize_ip)\n",
    "\n",
    "    df['src_port_category'] = df['src_port'].apply(categorize_port)\n",
    "    df['dst_port_category'] = df['dst_port'].apply(categorize_port)\n",
    "\n",
    "    ### Step 3: One-Hot Encode Protocol, IP Categories, and Port Categories\n",
    "    df = pd.get_dummies(df, columns=['protocol', 'src_ip_category', 'dst_ip_category', \n",
    "                                    'src_port_category', 'dst_port_category'], drop_first=True, dtype=int)\n",
    "\n",
    "    ### Step 4: Drop Original Categorical Columns\n",
    "    df.drop(columns=['src_ip', 'dst_ip', 'src_port', 'dst_port'], inplace=True)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], format='mixed')\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    df.replace({'benign': -1, 'malign': 1}, inplace=True)\n",
    "\n",
    "    return df.drop(columns=['flow_id', 'timestamp'])\n",
    "\n",
    "\n",
    "print(df_benign.shape)\n",
    "\n",
    "df = prepare_data(pd.concat([df_benign, df_ddos]))\n",
    "df_train = prepare_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52904, 123)\n",
      "(94535, 123)\n",
      "(147439, 124)\n"
     ]
    }
   ],
   "source": [
    "print(df_benign.shape)\n",
    "print(df_ddos.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: range(0, 123)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleksandr/miniconda3/envs/ucu/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleksandr/miniconda3/envs/ucu/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "                             Feature           VIF\n",
      "0                           duration  6.793976e+05\n",
      "1                      packets_count  7.402062e+10\n",
      "2                  fwd_packets_count  4.688100e+10\n",
      "3                  bwd_packets_count  1.154173e+10\n",
      "4                total_payload_bytes  7.510881e+10\n",
      "..                               ...           ...\n",
      "118            src_port_category_web  3.134922e+04\n",
      "119            dst_port_category_dns  1.503103e+00\n",
      "120          dst_port_category_other  1.681033e+04\n",
      "121  dst_port_category_remote_access  5.294180e+02\n",
      "122            dst_port_category_web  1.722585e+04\n",
      "\n",
      "[123 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "test = df.drop(columns=['label'])\n",
    "\n",
    "def calculate_vif(test):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = test.columns\n",
    "\n",
    "    vif = []\n",
    "    print(f\"Total: {range(test.shape[1])}\")\n",
    "    for i in range(test.shape[1]):\n",
    "        vif.append(variance_inflation_factor(test.values, i))\n",
    "        print(i)\n",
    "\n",
    "    vif_data[\"VIF\"] = vif\n",
    "    return vif_data\n",
    "\n",
    "vif_df = calculate_vif(test)\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>6.793976e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>packets_count</td>\n",
       "      <td>7.402062e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwd_packets_count</td>\n",
       "      <td>4.688100e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwd_packets_count</td>\n",
       "      <td>1.154173e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_payload_bytes</td>\n",
       "      <td>7.510881e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>src_port_category_web</td>\n",
       "      <td>3.134922e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>dst_port_category_dns</td>\n",
       "      <td>1.503103e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>dst_port_category_other</td>\n",
       "      <td>1.681033e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>dst_port_category_remote_access</td>\n",
       "      <td>5.294180e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>dst_port_category_web</td>\n",
       "      <td>1.722585e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Feature           VIF\n",
       "0                           duration  6.793976e+05\n",
       "1                      packets_count  7.402062e+10\n",
       "2                  fwd_packets_count  4.688100e+10\n",
       "3                  bwd_packets_count  1.154173e+10\n",
       "4                total_payload_bytes  7.510881e+10\n",
       "..                               ...           ...\n",
       "118            src_port_category_web  3.134922e+04\n",
       "119            dst_port_category_dns  1.503103e+00\n",
       "120          dst_port_category_other  1.681033e+04\n",
       "121  dst_port_category_remote_access  5.294180e+02\n",
       "122            dst_port_category_web  1.722585e+04\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['label'])  # Replace 'target' with your actual target column\n",
    "y = df['label']\n",
    "\n",
    "# Standardize the features for models like KNN & Lasso\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleksandr/miniconda3/envs/ucu/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.904e+01, tolerance: 1.086e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 numerical features using LassoCV.\n",
      "False\n",
      "KNN Accuracy after Lasso feature selection: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2017-07-07 07:59:50.315195    1\n",
       "2017-07-07 07:59:50.316273    1\n",
       "2017-07-07 08:00:35.337052    1\n",
       "2017-07-07 08:00:35.338671    1\n",
       "2017-07-07 08:00:35.342358    1\n",
       "                             ..\n",
       "2017-07-07 16:02:38.575222    1\n",
       "2017-07-07 16:02:39.565876    1\n",
       "2017-07-07 16:02:39.567285    1\n",
       "2017-07-07 16:02:40.805791    1\n",
       "2017-07-07 16:02:41.005391    1\n",
       "Name: requests_rate, Length: 147439, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"There are {X_train.shape[1]} features\")\n",
    "\n",
    "# Apply LassoCV to select numerical features\n",
    "lasso = LassoCV(cv=5, random_state=41).fit(X_train, y_train)\n",
    "selector = SelectFromModel(lasso, prefit=True, threshold=\"mean\")\n",
    "\n",
    "# Transform dataset with selected features\n",
    "X_train_lasso = selector.transform(X_train)\n",
    "X_test_lasso = selector.transform(X_test)\n",
    "\n",
    "print(f\"Selected {X_train_lasso.shape[1]} numerical features using LassoCV.\")\n",
    "\n",
    "# Train KNN with selected numerical features\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_lasso, y_train)\n",
    "\n",
    "# Evaluate KNN model\n",
    "y_pred_knn = knn.predict(X_test_lasso)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(np.allclose(y_pred_knn, y_test))\n",
    "\n",
    "print(f\"KNN Accuracy after Lasso feature selection: {knn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for KNN: ['dst_port_category_other' 'dst_port_category_remote_access'\n",
      " 'dst_port_category_web']\n"
     ]
    }
   ],
   "source": [
    "# Get boolean mask of selected features\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "# Get feature names from original dataframe\n",
    "selected_features = np.array(df.drop(columns=['label']).columns)[selected_mask]\n",
    "\n",
    "print(\"Selected Features for KNN:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: range(0, 3)\n",
      "0\n",
      "1\n",
      "2\n",
      "                           Feature  VIF\n",
      "0          dst_port_category_other  1.0\n",
      "1  dst_port_category_remote_access  1.0\n",
      "2            dst_port_category_web  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vif_df = calculate_vif(test[selected_features])\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00     10522\n",
      "     Anomaly       1.00      1.00      1.00     18966\n",
      "\n",
      "    accuracy                           1.00     29488\n",
      "   macro avg       1.00      1.00      1.00     29488\n",
      "weighted avg       1.00      1.00      1.00     29488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_model(y_pred_knn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg_funcs = {\n",
    "    # 'duration': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'packets_count': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_packets_count': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_total_payload_bytes': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'payload_bytes_mean': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'payload_bytes_std': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_payload_bytes_mean': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_payload_bytes_std': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_payload_bytes_variance': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_payload_bytes_mean': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_payload_bytes_std': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_payload_bytes_variance': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'max_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'min_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_min_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_std_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_mean_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_std_header_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_avg_segment_size': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_avg_segment_size': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_segment_size': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_init_win_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_init_win_bytes': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'active_min': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'active_max': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'idle_min': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'idle_std': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_bytes_rate': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'bwd_packets_rate': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_packets_rate': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'down_up_rate': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_fwd_bytes_per_bulk': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_fwd_packets_per_bulk': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_fwd_bulk_rate': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_bwd_packets_bulk_rate': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'avg_bwd_bulk_rate': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_bulk_state_count': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_bulk_total_size': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'bwd_bulk_state_count': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'bwd_bulk_total_size': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'ack_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'rst_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_fin_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_psh_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_syn_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_ack_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_rst_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'bwd_fin_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'bwd_ack_flag_counts': lambda x: x.sum() if not x.empty else 0,\n",
    "    # 'fwd_packets_IAT_std': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'fwd_packets_IAT_max': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'bwd_packets_IAT_mean': lambda x: x.mean() if not x.empty else 0,\n",
    "    # 'bwd_packets_IAT_max': lambda x: x.max() if not x.empty else 0,\n",
    "    # 'protocol_UDP': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'src_ip_category_subnet': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'dst_ip_category_subnet': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'src_port_category_dns': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'src_port_category_other': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'src_port_category_remote_access': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'src_port_category_web': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'dst_port_category_dns': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'dst_port_category_other': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'dst_port_category_remote_access': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    # 'dst_port_category_web': lambda x: x.mode().iloc[0] if not x.empty else 0,\n",
    "    'syn_flag_counts': 'sum',         # Total SYN packets in 1s\n",
    "    'rst_flag_counts': 'sum',         # Total RST packets in 1s\n",
    "    'ack_flag_counts': 'sum',         # Total ACK packets in 1s\n",
    "    #'duration': lambda x: x.mean() if not x.empty else 0,               # Avg duration of connections\n",
    "    'packets_count': 'sum',           # Total packets per second\n",
    "    'fwd_packets_count': 'sum',       # Total forward packets\n",
    "    'bytes_rate': lambda x: x.mean() if not x.empty else 0,             # Avg bytes per second\n",
    "    'requests_rate': 'count',          # Number of requests per aggregation period (1s by default)\n",
    "    'label': lambda x: x.max() if not x.empty else -1,\n",
    "}\n",
    "\n",
    "# Resample and aggregate\n",
    "df_resampled = df.resample('1s').agg(agg_funcs)\n",
    "train_resampled = df_train.resample('1s').agg(agg_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syn_flag_counts</th>\n",
       "      <th>rst_flag_counts</th>\n",
       "      <th>ack_flag_counts</th>\n",
       "      <th>packets_count</th>\n",
       "      <th>fwd_packets_count</th>\n",
       "      <th>bytes_rate</th>\n",
       "      <th>requests_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-07 07:59:50</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>687</td>\n",
       "      <td>687</td>\n",
       "      <td>453</td>\n",
       "      <td>96.412162</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 07:59:51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 07:59:52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 07:59:53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 07:59:54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 16:02:37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 16:02:38</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>115</td>\n",
       "      <td>58</td>\n",
       "      <td>10961.071985</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 16:02:39</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>3779.565881</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 16:02:40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07 16:02:41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28972 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     syn_flag_counts  rst_flag_counts  ack_flag_counts  packets_count  fwd_packets_count    bytes_rate  requests_rate  label\n",
       "datetime                                                                                                                                    \n",
       "2017-07-07 07:59:50                0                2              687            687                453     96.412162              2     -1\n",
       "2017-07-07 07:59:51                0                0                0              0                  0      0.000000              0     -1\n",
       "2017-07-07 07:59:52                0                0                0              0                  0      0.000000              0     -1\n",
       "2017-07-07 07:59:53                0                0                0              0                  0      0.000000              0     -1\n",
       "2017-07-07 07:59:54                0                0                0              0                  0      0.000000              0     -1\n",
       "...                              ...              ...              ...            ...                ...           ...            ...    ...\n",
       "2017-07-07 16:02:37                0                0                1              1                  0      0.000000              1     -1\n",
       "2017-07-07 16:02:38                8                0              111            115                 58  10961.071985              2     -1\n",
       "2017-07-07 16:02:39                4                0               86             88                 42   3779.565881              2     -1\n",
       "2017-07-07 16:02:40                0                0                3              3                  0      0.000000              1     -1\n",
       "2017-07-07 16:02:41                0                0                1              1                  0      0.000000              1     -1\n",
       "\n",
       "[28972 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.26      0.00      0.01     27889\n",
      "     Anomaly       0.03      0.81      0.06      1083\n",
      "\n",
      "    accuracy                           0.03     28972\n",
      "   macro avg       0.15      0.40      0.03     28972\n",
      "weighted avg       0.25      0.03      0.01     28972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = IsolationForest(contamination=0.01, random_state=42)\n",
    "y_pred = model.fit_predict(df_resampled.drop(columns=['label']))\n",
    "score_model(y_pred, df_resampled['label'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
