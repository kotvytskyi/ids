{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave this code here to play with it later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# # -----------------------------\n",
    "# # 1. PREPARE DATA\n",
    "# # -----------------------------\n",
    "# # Suppose your combined_data_agg has a 'label' column (0 for benign, 1 for attack).\n",
    "# # If your label column is named differently, adjust accordingly.\n",
    "# df = combined.drop(columns=['flow_id', 'timestamp', 'src_ip', 'dst_ip']).copy()\n",
    "\n",
    "# # Separate features (X) and target (y)\n",
    "# X = df.drop(columns=['label'])  # drop the target column\n",
    "# y = df['label']\n",
    "\n",
    "# # -----------------------------\n",
    "# # 2. TIME-AWARE SPLIT\n",
    "# # -----------------------------\n",
    "# # We'll demonstrate how to do multiple time-series splits for model validation.\n",
    "# # For instance, we create 3 splits in chronological order.\n",
    "# tscv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "# # We'll store selected feature sets and validation scores\n",
    "# feature_subsets = []\n",
    "# val_scores = []\n",
    "\n",
    "# for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "#     print(f\"\\n--- Fold {fold_idx + 1} ---\")\n",
    "    \n",
    "#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "#     # -----------------------------\n",
    "#     # 3. TRAIN A MODEL & SELECT FEATURES\n",
    "#     # -----------------------------\n",
    "#     # Example: Recursive Feature Elimination (RFE) with a Random Forest\n",
    "#     model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "#     # n_features_to_select: you decide how many you want to keep\n",
    "#     # (can be tuned depending on your data size and domain knowledge).\n",
    "#     rfe = RFE(estimator=model, n_features_to_select=20, step=1)\n",
    "    \n",
    "#     # Fit RFE on training set only\n",
    "#     rfe.fit(X_train, y_train)\n",
    "    \n",
    "#     # Which features were selected?\n",
    "#     selected_mask = rfe.support_\n",
    "#     selected_features = X.columns[selected_mask]\n",
    "#     feature_subsets.append(selected_features)\n",
    "    \n",
    "#     print(\"Selected features:\", list(selected_features))\n",
    "    \n",
    "#     # Evaluate on the validation set\n",
    "#     val_score = rfe.score(X_val, y_val)\n",
    "#     val_scores.append(val_score)\n",
    "#     print(\"Validation Accuracy:\", val_score)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 4. REVIEW SELECTED FEATURES\n",
    "# # -----------------------------\n",
    "# # After the loop, you might look at how stable the selection was across splits:\n",
    "# print(\"\\nSelected features for each fold:\")\n",
    "# for i, fset in enumerate(feature_subsets, 1):\n",
    "#     print(f\"  Fold {i}: {list(fset)}\")\n",
    "\n",
    "# print(\"\\nValidation scores across folds:\", val_scores)\n",
    "# print(\"Average Validation Score:\", np.mean(val_scores))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
